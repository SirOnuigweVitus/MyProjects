{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID19_Prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPltgE8OR9zBg/6qYoOWahe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SirOnuigweVitus/MyProjects/blob/master/COVID19_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUS1wHtVqb3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "05e1bc74-17bd-4cdc-af01-f015a7ed2501"
      },
      "source": [
        "!unzip dataset.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  dataset.zip\n",
            "replace dataset/test_set/covid/covid1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: dataset/test_set/covid/covid1.jpg  \n",
            "  inflating: dataset/test_set/covid/covid15.jpeg  \n",
            "  inflating: dataset/test_set/covid/covid2.jpg  \n",
            "  inflating: dataset/test_set/covid/covid25.jpeg  \n",
            "  inflating: dataset/test_set/covid/covid3.jpg  \n",
            "  inflating: dataset/test_set/normal/normal1.jpeg  \n",
            "  inflating: dataset/test_set/normal/normal16.jpeg  \n",
            "  inflating: dataset/test_set/normal/normal2.jpeg  \n",
            "  inflating: dataset/test_set/normal/normal23.jpeg  \n",
            "  inflating: dataset/test_set/normal/normal9.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid10.jpg  \n",
            "  inflating: dataset/training_set/covid/covid11.jpg  \n",
            "  inflating: dataset/training_set/covid/covid12.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid13.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid14.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid16.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid17.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid18.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid19.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid20.jpg  \n",
            "  inflating: dataset/training_set/covid/covid21.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid22.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid23.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid24.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid4.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid5.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid6.jpg  \n",
            "  inflating: dataset/training_set/covid/covid7.jpg  \n",
            "  inflating: dataset/training_set/covid/covid8.jpeg  \n",
            "  inflating: dataset/training_set/covid/covid9.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal10.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal11.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal12.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal13.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal14.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal15.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal17.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal18.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal19.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal20.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal21.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal22.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal24.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal25.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal3.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal4.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal5.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal6.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal7.jpeg  \n",
            "  inflating: dataset/training_set/normal/normal8.jpeg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r12lU3__o-Um",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e9ed9e2-2f5a-4ca9-8edb-e5877cdb0b9d"
      },
      "source": [
        "# part 1 - building the CNN model for image classification\n",
        "# importing the keras libraries and packages\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2FyMg0Sq_v8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initializing the CNN\n",
        "classifier = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV-RnQebrHcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ed6f3b30-d0ba-4fd8-e7dd-4760c54cd452"
      },
      "source": [
        "# step 1 - convolution\n",
        "classifier.add(Convolution2D(64, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PMJoP8qrO5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# step 2 - pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqKVPRmMrWXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6cc39423-666f-42da-8aa8-b547bdc5f175"
      },
      "source": [
        "# adding second convolutional layer to increase the accuracy outcome\n",
        "classifier.add(Convolution2D(64, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY5RDP1Aracg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# step 3 - flattening\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89gcGWThrgoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7d104b1b-3ce2-4af6-f6b6-440a5b823ab1"
      },
      "source": [
        "# step 4 - full connection\n",
        "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
        "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDdWIEf0rlKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYC-a3KKrq1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0aNhI9CryBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7a5c5d6a-3122-425f-a52c-0c5f07fbe913"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                  target_size=(64, 64),\n",
        "                                                  batch_size=32,\n",
        "                                                  class_mode='binary')\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size=(64, 64),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='binary')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40 images belonging to 2 classes.\n",
            "Found 10 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5nkdvBwuVea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "1cd5488e-bcd7-4052-be1d-cd9c03932a3f"
      },
      "source": [
        "classifier.fit(training_set,\n",
        "          steps_per_epoch=40,\n",
        "          epochs=25,\n",
        "          validation_data=test_set,\n",
        "          validation_steps=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "40/40 [==============================] - 24s 589ms/step - loss: 0.4618 - accuracy: 0.8025 - val_loss: 0.5270 - val_accuracy: 0.9000\n",
            "Epoch 2/25\n",
            "40/40 [==============================] - 20s 506ms/step - loss: 0.0817 - accuracy: 0.9688 - val_loss: 0.6548 - val_accuracy: 0.9000\n",
            "Epoch 3/25\n",
            "40/40 [==============================] - 20s 506ms/step - loss: 0.0396 - accuracy: 0.9800 - val_loss: 1.1753 - val_accuracy: 0.9000\n",
            "Epoch 4/25\n",
            "40/40 [==============================] - 20s 507ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 1.2292 - val_accuracy: 0.9000\n",
            "Epoch 5/25\n",
            "40/40 [==============================] - 20s 506ms/step - loss: 0.0054 - accuracy: 0.9975 - val_loss: 1.4772 - val_accuracy: 0.9000\n",
            "Epoch 6/25\n",
            "40/40 [==============================] - 20s 506ms/step - loss: 0.0064 - accuracy: 0.9962 - val_loss: 1.6921 - val_accuracy: 0.9000\n",
            "Epoch 7/25\n",
            "40/40 [==============================] - 20s 499ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0150 - val_accuracy: 0.9000\n",
            "Epoch 8/25\n",
            "40/40 [==============================] - 19s 486ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 2.3073 - val_accuracy: 0.8000\n",
            "Epoch 9/25\n",
            "40/40 [==============================] - 18s 461ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.9359 - val_accuracy: 0.9000\n",
            "Epoch 10/25\n",
            "40/40 [==============================] - 19s 469ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1107 - val_accuracy: 0.9000\n",
            "Epoch 11/25\n",
            "40/40 [==============================] - 19s 469ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.2080 - val_accuracy: 0.9000\n",
            "Epoch 12/25\n",
            "40/40 [==============================] - 18s 458ms/step - loss: 0.1212 - accuracy: 0.9475 - val_loss: 1.0062 - val_accuracy: 0.9000\n",
            "Epoch 13/25\n",
            "40/40 [==============================] - 18s 457ms/step - loss: 0.0237 - accuracy: 0.9900 - val_loss: 0.9737 - val_accuracy: 0.9000\n",
            "Epoch 14/25\n",
            "40/40 [==============================] - 18s 446ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1590 - val_accuracy: 0.9000\n",
            "Epoch 15/25\n",
            "40/40 [==============================] - 18s 456ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 1.2004 - val_accuracy: 0.9000\n",
            "Epoch 16/25\n",
            "40/40 [==============================] - 18s 451ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 1.3160 - val_accuracy: 0.9000\n",
            "Epoch 17/25\n",
            "40/40 [==============================] - 18s 446ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3007 - val_accuracy: 0.9000\n",
            "Epoch 18/25\n",
            "40/40 [==============================] - 18s 449ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6008 - val_accuracy: 0.9000\n",
            "Epoch 19/25\n",
            "40/40 [==============================] - 18s 456ms/step - loss: 7.7788e-04 - accuracy: 1.0000 - val_loss: 1.7517 - val_accuracy: 0.9000\n",
            "Epoch 20/25\n",
            "40/40 [==============================] - 18s 452ms/step - loss: 6.9398e-04 - accuracy: 1.0000 - val_loss: 1.7328 - val_accuracy: 0.9000\n",
            "Epoch 21/25\n",
            "40/40 [==============================] - 18s 451ms/step - loss: 2.3274e-04 - accuracy: 1.0000 - val_loss: 1.7041 - val_accuracy: 0.9000\n",
            "Epoch 22/25\n",
            "40/40 [==============================] - 18s 449ms/step - loss: 5.0465e-04 - accuracy: 1.0000 - val_loss: 1.7328 - val_accuracy: 0.9000\n",
            "Epoch 23/25\n",
            "40/40 [==============================] - 18s 446ms/step - loss: 3.0910e-04 - accuracy: 1.0000 - val_loss: 1.7133 - val_accuracy: 0.9000\n",
            "Epoch 24/25\n",
            "40/40 [==============================] - 18s 451ms/step - loss: 1.3911e-04 - accuracy: 1.0000 - val_loss: 1.7606 - val_accuracy: 0.9000\n",
            "Epoch 25/25\n",
            "40/40 [==============================] - 18s 446ms/step - loss: 2.6860e-04 - accuracy: 1.0000 - val_loss: 1.8404 - val_accuracy: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7efdc023bf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjRxy_dI6oND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "7dfb66fb-bf59-4e93-e6e1-5224ed3502ef"
      },
      "source": [
        "#Confusion Matrix and Classification Report\n",
        " validation_data=test_set\n",
        " validation_steps=10\n",
        " batch_size=32\n",
        " import numpy as np\n",
        " import argparse\n",
        " from sklearn.metrics import confusion_matrix\n",
        " from sklearn.metrics import classification_report\n",
        " Y_pred = classifier.predict_generator(validation_data, validation_steps // \n",
        " batch_size+1)\n",
        " y_pred = np.argmax(Y_pred, axis=1)\n",
        " \n",
        " print('Confusion Matrix')\n",
        " print(confusion_matrix(validation_data.classes, y_pred))\n",
        " print('Classification Report')\n",
        " target_names = ['covid', 'normal']\n",
        " print(classification_report(validation_data.classes, y_pred, \n",
        " target_names=target_names))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[5 0]\n",
            " [5 0]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       covid       0.50      1.00      0.67         5\n",
            "      normal       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.50        10\n",
            "   macro avg       0.25      0.50      0.33        10\n",
            "weighted avg       0.25      0.50      0.33        10\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}